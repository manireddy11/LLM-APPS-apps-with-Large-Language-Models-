ğŸ“¡ RouteLLM Chat App

Inspired by the open-source RouteLLM library
, this app shows how queries can be routed intelligently between different language models for optimal performance and efficiency.

ğŸš€ What is it?

A Streamlit-based chat application that automatically decides which AI model should handle your query. Instead of relying on a single model, it leverages multiple LLMs and dynamically routes tasks to the most suitable oneâ€”balancing speed, cost, and quality.

âœ¨ Key Features

ğŸ’¬ Interactive Chat UI â€“ Simple interface for AI conversations

ğŸ¤– Smart Model Routing â€“ Queries are sent to the best model depending on complexity

ğŸ”€ Hybrid Model Setup â€“ Combines GPT-4 (mini) for complex reasoning with Meta-Llama 3.1 (70B Turbo) for lightweight tasks

ğŸ“œ Response Transparency â€“ Each answer includes details about which model was used

ğŸ—‚ï¸ Chat History Tracking â€“ Keeps a full record of messages along with model selections

âš™ï¸ How It Works

Initialization â€“ RouteLLM is configured with two models:

ğŸ‹ï¸ Strong model â†’ GPT-4 (mini)

ğŸª¶ Efficient model â†’ Meta-Llama 3.1 70B Instruct Turbo

User Input â€“ The user types a query in the chat box.

Routing Logic â€“ RouteLLM evaluates the queryâ€™s complexity and selects the optimal model.

Response Generation â€“ The chosen model produces a reply.

Display â€“ The response is shown with the model label for full transparency.

History â€“ The conversation log, including model usage, is stored and displayed.
